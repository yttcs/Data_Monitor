{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eaefa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime \n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import yagmail\n",
    "import requests\n",
    "\n",
    "import schedule\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a new datafile, time stamp it, and compare it to the last downloaded datafile\n",
    "\n",
    "def pollData(): \n",
    "\n",
    "# download datafile as a DF\n",
    "\n",
    "    earthquake = pd.read_csv('http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/significant_month.csv')\n",
    "\n",
    "# create a date_time stamp (global)\n",
    "    \n",
    "    global dt_stamp\n",
    "\n",
    "    dt_stamp=datetime.now().strftime(\"%m%d%Y_%H%M%S\")\n",
    "\n",
    "# save the file as a .csv with a unique date_time stamp (in the working directory)\n",
    "\n",
    "    earthquake.to_csv(f\"eq_csv_{dt_stamp}.csv\") \n",
    "    \n",
    "# Get all the relevant .csv files (previously downloaded earthquake datafiles) in the downlaod directory and get their\n",
    "# creation date times\n",
    "\n",
    "    date_list=[]\n",
    "    file_list=[]\n",
    "    for path in Path().glob(\"eq*.csv\"):   #Path() is empty because we're getting file from the current working directory\n",
    "        create_datetime = os.stat(path).st_ctime\n",
    "        date_list.append(datetime.fromtimestamp(create_datetime))\n",
    "        file_list.append(path)\n",
    "             \n",
    "    if len(file_list) == 1: # If it's the first download\n",
    "                  \n",
    "        f1 = file_list[-1]\n",
    "        \n",
    "        newl=[]\n",
    "        with open(f1,encoding = 'utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:      \n",
    "                newl.append(row)\n",
    "           \n",
    "        for i in newl:\n",
    "            i.pop(0)\n",
    "       \n",
    "        notify_data=[a for a in newl] \n",
    "        \n",
    "        notify_data.pop(0) # we strip the headers here so that both notify_data versions in the if/else match up for the getData() function \n",
    "              \n",
    "    else:\n",
    "        \n",
    "        # Assign the last two positions of 'file_list' and put them in two seperate lists\n",
    "        # This corresponds to the two latest earthquake datafile downloads \n",
    "        \n",
    "        f1 = file_list[-1]  # the latest download\n",
    "        f2 = file_list[-2]  # the previous download\n",
    "    \n",
    "        newl=[]\n",
    "        with open(f1,encoding = 'utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:      \n",
    "                newl.append(row)        \n",
    "        \n",
    "        oldl=[]\n",
    "        with open(f2, encoding = 'utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                oldl.append(row)   \n",
    "        \n",
    "       # Get rid of the the row numbers (the first element) in the lists so that they won't interfere when we compare \n",
    "       # the two lists against each other\n",
    "\n",
    "        for i in newl:\n",
    "            i.pop(0)\n",
    "    \n",
    "        for i in oldl:\n",
    "            i.pop(0)        \n",
    "            \n",
    "        # Compare the two lists and extract only new data (earthquakes) into a new 'notify_data' list (using a list comprehension)\n",
    "                        \n",
    "        notify_data=[a for a in newl if a not in [b for b in oldl]] \n",
    "            \n",
    "# If notify_data isn't empty then save it to disk, and call getUpdate() to create a \n",
    "# visualization, and continue the process. Otherwise, delete the redundant datafile download.\n",
    "\n",
    "# headers, quotes around values in the 'place' feature and other things, are getting stripped as undesired side \n",
    "#   effects of the comparison, so we fix that first. Also have to add the row numbers back in, so that \n",
    "#   everything will match up when we write the .csv to disk to have the exact same formating as the original download that the differences \n",
    "#   were extracted from. \n",
    " \n",
    "    if len(notify_data) != 0:\n",
    "        \n",
    "        # get the headers and clean them up.       \n",
    "        new_headers = str(newl[0]) \n",
    "        new_headers = new_headers.replace('[',',').replace(']','').replace(\"'\",'').replace(' ','') \n",
    "        new_headers = new_headers.split(\",\")\n",
    "                   \n",
    "        # add quotes back to the values in the 'place' feature\n",
    "        for i in notify_data: \n",
    "            i[13] = '\"' + i[13] + '\"'\n",
    "         \n",
    "        # add index numbers to data rows\n",
    "        for idx, i in enumerate(notify_data):\n",
    "            i.insert(0,idx)\n",
    "        \n",
    "        # add headers back in, and save as .csv to disk\n",
    "        notify_data.insert(0, new_headers) \n",
    "                        \n",
    "        with open('notify_data_' + dt_stamp + '.csv' , 'w', encoding=\"utf-8\") as f:\n",
    "            for row in notify_data:\n",
    "                for x in row:\n",
    "                    f.write(str(x) + ',')\n",
    "                \n",
    "                f.write('\\n')\n",
    "               \n",
    "        # call the get update function     \n",
    "        getUpdate(notify_data)  \n",
    "         \n",
    "    else:\n",
    "        print(\"No Update\")  \n",
    "                \n",
    "        #delete the redundant datafile download    \n",
    "        files = glob.glob(\"eq*.csv\")\n",
    "        os.unlink(files[-1])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725dc739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that visualises update and saves file for email attachment\n",
    "\n",
    "def getUpdate(notify_data):\n",
    "   \n",
    "    fig = plt.figure(figsize=(45,30))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "# remove the column numbers again so they don't interfere with the dataframe index\n",
    "\n",
    "    for i in notify_data:\n",
    "        i.pop(0)\n",
    "\n",
    "# Create a DF fron notify_data list\n",
    "    notify_DF = pd.DataFrame(notify_data[1:], columns=notify_data[0])\n",
    "    \n",
    "# Get only the columns we want\n",
    "    notify_DF = notify_DF[['time','latitude','longitude','depth','mag','place']]\n",
    "    \n",
    "# Convert the location columns to float\n",
    "    notify_DF[['longitude','latitude']] = notify_DF[['longitude','latitude']].astype(float)\n",
    "\n",
    "# Now we have differences from the newest file only\n",
    "# save back to a csv from a DF and put a timestamp in the filename\n",
    "# Now we can visualize any new datapoints and send an email accordingly\n",
    "\n",
    "    filename = datetime.now().strftime('notify_%d%m%Y_%H%M%S.csv')\n",
    "    notify_DF.to_csv(r'c://Users//ADMIN//filename')\n",
    "   \n",
    "    lats=notify_DF['latitude'].to_list()\n",
    "    lons=notify_DF['longitude'].to_list()\n",
    "    place=notify_DF['place'].to_list()\n",
    "\n",
    "# Visualize the Data\n",
    "\n",
    "    m = Basemap(projection='mill',area_thresh= 10)\n",
    "\n",
    "    m.drawcoastlines(color='black', linewidth=0.25)\n",
    "    m.fillcontinents(color='coral',lake_color='aqua')\n",
    "    m.drawmapboundary(fill_color='aqua')\n",
    "\n",
    "    x,y = m(lons,lats)\n",
    "    m.scatter(x,y, marker='o', color='black', s = 100, alpha=1)\n",
    "\n",
    "    date = datetime.utcnow()\n",
    "    plt.title(\"Significant Earthquakes update as of UTC %s\" % date.strftime(\"%b %d %Y %H:%M\"),fontsize = 30, fontweight='bold')\n",
    "\n",
    "    # create map legend \n",
    "    \n",
    "    from matplotlib.patches import Rectangle\n",
    "    hndls = [] \n",
    "    for i in range(len(notify_DF.index)):\n",
    "    #hndls.append(Rectangle((0, 0), 0, 0, color = 'black', alpha=0.5)) \n",
    "        hndls.append(plt.Circle((0,0),5, color = 'black'))\n",
    "  \n",
    "    ax.legend(hndls, notify_DF.place, loc = 'lower right', fontsize = 30, edgecolor = 'black', facecolor = 'white', handlelength = 1, framealpha = .4 )    \n",
    "\n",
    "    # Save visualization, with a datetime stamp             \n",
    "    plt.savefig('c://Users//ADMIN//email_project//update_' + dt_stamp + '.png') \n",
    "    \n",
    "    # get all the images in the image directory and assign the latest one, by timestamp, to 'latest update' variable\n",
    "    \n",
    "    update_list=[] \n",
    "    for path in Path().glob(\"email_project//*.png\"):   \n",
    "        update_list.append(path) \n",
    "    \n",
    "    global latest_update   \n",
    "    latest_update = max(update_list)  \n",
    "    \n",
    "    sendEmail()\n",
    "    \n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df416fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send Email using Yagmail\n",
    "\n",
    "def sendEmail():\n",
    "     \n",
    "    file_list2=[]\n",
    "    for path in Path().glob('email_project/*.png'): \n",
    "        file_list2.append(path)\n",
    "\n",
    "    try:\n",
    "    \n",
    "    #initializing the server connection\n",
    "    \n",
    "    #two factor + app password\n",
    "        yag = yagmail.SMTP('gmail address goes here', 'app password goes here')\n",
    "    \n",
    "    #sending the email\n",
    "    \n",
    "        to = 'test@domain.com'  # target email goes here (in quotes)\n",
    "        subject = 'Update'\n",
    "        content = 'Here is the latest update'\n",
    "        attachments= max(file_list2)\n",
    "                 \n",
    "        yag.send(to, subject, content, attachments)\n",
    "        print(\"Email sent successfully.\")\n",
    "    except:\n",
    "        print(\"Error, email was not sent\")  \n",
    "        \n",
    "        # call the sendsms to notify of email update\n",
    "        \n",
    "        sendsms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send SMS using Textbelt\n",
    "\n",
    "def sendsms():\n",
    "\n",
    "    resp = requests.post('https://textbelt.com/text', {\n",
    "      'phone': '1111111111',   # target phone number goes here (in quotes)\n",
    "      'message': 'Earthquakes update sent to email',\n",
    "      'key': 'textbelt',\n",
    "    })\n",
    "    print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0745b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an interval to check for updates (call the 'pollData' function)\n",
    "\n",
    "schedule.every(30).seconds.do(pollData)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec91b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "gis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
